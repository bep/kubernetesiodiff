<html>
<body>
<h1>
  API Priority and Fairness
</h1>
<p>
  <a href="https://github.com/kubernetes/website/edit/master/content/en/docs/concepts/cluster-administration/flow-control.md" id="editPageButton" target="_blank">
    Edit This Page
  </a>
</p>
<h1>
  API Priority and Fairness
</h1>
<div style="margin-top: 10px; margin-bottom: 10px;">
<p>
  <b>
    FEATURE STATE:
  </b>
  <code>
    Kubernetes v1.18
  </code>
</p>
<p>
  <a href="#" id="feature-state-dialog-link" class="ui-state-default ui-corner-all">
    <span class="ui-icon ui-icon-newwin"></span>
    alpha
  </a>
</p>
<div id="feature-state-dialog" class="ui-dialog-content" title="alpha">
  <p>
    This feature is currently in a
    <em>
      alpha
    </em>
    state, meaning:
  </p>
  <ul>
    <li>
      The version names contain alpha (e.g. v1alpha1).
    </li>
    <li>
      Might be buggy. Enabling the feature may expose bugs. Disabled by default.
    </li>
    <li>
      Support for feature may be dropped at any time without notice.
    </li>
    <li>
      The API may change in incompatible ways in a later software release without notice.
    </li>
    <li>
      Recommended for use only in short-lived testing clusters, due to increased risk of bugs and lack of long-term support.
    </li>
  </ul>
</div>
<script>
  $(function(){
  <pre><code>$( &quot;#feature-state-dialog&quot; ).dialog({
  autoOpen: false,
  width: &quot;600&quot;,
  buttons: [
  {
  text: &quot;Ok&quot;,
  click: function() {
  $( this ).dialog( &quot;close&quot; );
  }
  }
  ]
  });


  $( &quot;#feature-state-dialog-link&quot; ).click(function( event ) {
  $( &quot;#feature-state-dialog&quot; ).dialog( &quot;open&quot; );
  event.preventDefault();
  });</code></pre>
  <p>});
</script>
<p>
  Controlling the behavior of the Kubernetes API server in an overload situation
  is a key task for cluster administrators. The
  <a class='glossary-tooltip' href='/docs/reference/generated/kube-apiserver/' target='_blank'>
    kube-apiserver
    <span class='tooltip-text'>
      Control plane component that serves the Kubernetes API.
    </span>
  </a>
  has some controls available
  (i.e. the
  <code>
    --max-requests-inflight
  </code>
  and
  <code>
    --max-mutating-requests-inflight
  </code>
  command-line flags) to limit the amount of outstanding work that will be
  accepted, preventing a flood of inbound requests from overloading and
  potentially crashing the API server, but these flags are not enough to ensure
  that the most important requests get through in a period of high traffic.
</p>
<p>
  The API Priority and Fairness feature (APF) is an alternative that improves upon
  aforementioned max-inflight limitations. APF classifies
  and isolates requests in a more fine-grained way. It also introduces
  a limited amount of queuing, so that no requests are rejected in cases
  of very brief bursts.  Requests are dispatched from queues using a
  fair queuing technique so that, for example, a poorly-behaved
  <a class='glossary-tooltip' href='/docs/concepts/architecture/controller/' target='_blank'>
    controller
    <span class='tooltip-text'>
      A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.
    </span>
  </a>
  need not
  starve others (even at the same priority level).
</p>
<blockquote class="caution">
  <div>
    <strong>
      Caution:
    </strong>
    Requests classified as &ldquo;long-running&rdquo; — primarily watches — are not
    subject to the API Priority and Fairness filter. This is also true for
    the
    <code>
      --max-requests-inflight
    </code>
    flag without the API Priority and
    Fairness feature enabled.
  </div>
</blockquote>
<ul id="markdown-toc">
  <li>
    <a href="#enabling-api-priority-and-fairness">
      Enabling API Priority and Fairness
    </a>
  </li>
  <li>
    <a href="#concepts">
      Concepts
    </a>
  </li>
  <li>
    <a href="#defaults">
      Defaults
    </a>
  </li>
  <li>
    <a href="#resources">
      Resources
    </a>
  </li>
  <li>
    <a href="#diagnostics">
      Diagnostics
    </a>
  </li>
  <li>
    <a href="#observability">
      Observability
    </a>
  </li>
  <li>
    <a href="#what-s-next">
      What's next
    </a>
  </li>
</ul>
<h2 id="enabling-api-priority-and-fairness">
  Enabling API Priority and Fairness
</h2>
<p>
  The API Priority and Fairness feature is controlled by a feature gate
  and is not enabled by default.  See
  <a href="/docs/reference/command-line-tools-reference/feature-gates/">
    Feature Gates
  </a>
  for a general explanation of feature gates and how to enable and disable them.  The
  name of the feature gate for APF is &ldquo;APIPriorityAndFairness&rdquo;.  This
  feature also involves an
  <a class='glossary-tooltip' href='/docs/concepts/overview/kubernetes-api/#api-groups' target='_blank'>
    API Group
    <span class='tooltip-text'>
      A set of related paths in the Kubernetes API.
    </span>
  </a>
  that must be enabled.  You can do these
  things by adding the following command-line flags to your
  <code>
    kube-apiserver
  </code>
  invocation:
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kube-apiserver <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>--feature-gates<span style="color:#666">=</span><span style="color:#b8860b">APIPriorityAndFairness</span><span style="color:#666">=</span><span style="color:#a2f">true</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>--runtime-config<span style="color:#666">=</span>flowcontrol.apiserver.k8s.io/v1alpha1<span style="color:#666">=</span><span style="color:#a2f">true</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span> <span style="color:#080;font-style:italic"># …and other flags as usual</span></code></pre>
</div>
<p>
  The command-line flag
  <code>
    --enable-priority-and-fairness=false
  </code>
  will disable the
  API Priority and Fairness feature, even if other flags have enabled it.
</p>
<h2 id="concepts">
  Concepts
</h2>
<p>
  There are several distinct features involved in the API Priority and Fairness
  feature. Incoming requests are classified by attributes of the request using
  <em>
    FlowSchemas
  </em>
  , and assigned to priority levels. Priority levels add a degree of
  isolation by maintaining separate concurrency limits, so that requests assigned
  to different priority levels cannot starve each other. Within a priority level,
  a fair-queuing algorithm prevents requests from different
  <em>
    flows
  </em>
  from starving
  each other, and allows for requests to be queued to prevent bursty traffic from
  causing failed requests when the average load is acceptably low.
</p>
<h3 id="priority-levels">
  Priority Levels
</h3>
<p>
  Without APF enabled, overall concurrency in
  the API server is limited by the
  <code>
    kube-apiserver
  </code>
  flags
  <code>
    --max-requests-inflight
  </code>
  and
  <code>
    --max-mutating-requests-inflight
  </code>
  . With APF
  enabled, the concurrency limits defined by these flags are summed and then the sum is divided up
  among a configurable set of
  <em>
    priority levels
  </em>
  . Each incoming request is assigned
  to a single priority level, and each priority level will only dispatch as many
  concurrent requests as its configuration allows.
</p>
<p>
  The default configuration, for example, includes separate priority levels for
  leader-election requests, requests from built-in controllers, and requests from
  Pods. This means that an ill-behaved Pod that floods the API server with
  requests cannot prevent leader election or actions by the built-in controllers
  from succeeding.
</p>
<h3 id="queuing">
  Queuing
</h3>
<p>
  Even within a priority level there may be a large number of distinct sources of
  traffic. In an overload situation, it is valuable to prevent one stream of
  requests from starving others (in particular, in the relatively common case of a
  single buggy client flooding the kube-apiserver with requests, that buggy client
  would ideally not have much measurable impact on other clients at all). This is
  handled by use of a fair-queuing algorithm to process requests that are assigned
  the same priority level. Each request is assigned to a
  <em>
    flow
  </em>
  , identified by the
  name of the matching FlowSchema plus a
  <em>
    flow distinguisher
  </em>
  — which
  is either the requesting user, the target resource&rsquo;s namespace, or nothing — and the
  system attempts to give approximately equal weight to requests in different
  flows of the same priority level.
</p>
<p>
  After classifying a request into a flow, the API Priority and Fairness
  feature then may assign the request to a queue.  This assignment uses
  a technique known as
  <a class='glossary-tooltip' href='/dir2/docs/reference/glossary/?all=true#term-shuffle-sharding' target='_blank'>
    shuffle sharding
    <span class='tooltip-text'>
      A technique for assigning requests to queues that provides better isolation than hashing modulo the number of queues.
    </span>
  </a>
  , which makes relatively efficient use of
  queues to insulate low-intensity flows from high-intensity flows.
</p>
<p>
  The details of the queuing algorithm are tunable for each priority level, and
  allow administrators to trade off memory use, fairness (the property that
  independent flows will all make progress when total traffic exceeds capacity),
  tolerance for bursty traffic, and the added latency induced by queuing.
</p>
<h3 id="exempt-requests">
  Exempt requests
</h3>
<p>
  Some requests are considered sufficiently important that they are not subject to
  any of the limitations imposed by this feature. These exemptions prevent an
  improperly-configured flow control configuration from totally disabling an API
  server.
</p>
<h2 id="defaults">
  Defaults
</h2>
<p>
  The Priority and Fairness feature ships with a suggested configuration that
  should suffice for experimentation; if your cluster is likely to
  experience heavy load then you should consider what configuration will work best. The suggested configuration groups requests into five priority
  classes:
</p>
<ul>
  <li>
    <p>
      The
      <code>
        system
      </code>
      priority level is for requests from the
      <code>
        system:nodes
      </code>
      group,
      i.e. Kubelets, which must be able to contact the API server in order for
      workloads to be able to schedule on them.
    </p>
  </li>
  <li>
    <p>
      The
      <code>
        leader-election
      </code>
      priority level is for leader election requests from
      built-in controllers (in particular, requests for
      <code>
        endpoints
      </code>
      ,
      <code>
        configmaps
      </code>
      ,
      or
      <code>
        leases
      </code>
      coming from the
      <code>
        system:kube-controller-manager
      </code>
      or
      <code>
        system:kube-scheduler
      </code>
      users and service accounts in the
      <code>
        kube-system
      </code>
      namespace). These are important to isolate from other traffic because failures
      in leader election cause their controllers to fail and restart, which in turn
      causes more expensive traffic as the new controllers sync their informers.
    </p>
  </li>
  <li>
    <p>
      The
      <code>
        workload-high
      </code>
      priority level is for other requests from built-in
      controllers.
    </p>
  </li>
  <li>
    <p>
      The
      <code>
        workload-low
      </code>
      priority level is for requests from any other service
      account, which will typically include all requests from controllers runing in
      Pods.
    </p>
  </li>
  <li>
    <p>
      The
      <code>
        global-default
      </code>
      priority level handles all other traffic, e.g.
      interactive
      <code>
        kubectl
      </code>
      commands run by nonprivileged users.
    </p>
  </li>
</ul>
<p>
  Additionally, there are two PriorityLevelConfigurations and two FlowSchemas that
  are built in and may not be overwritten:
</p>
<ul>
  <li>
    <p>
      The special
      <code>
        exempt
      </code>
      priority level is used for requests that are not subject
      to flow control at all: they will always be dispatched immediately. The
      special
      <code>
        exempt
      </code>
      FlowSchema classifies all requests from the
      <code>
        system:masters
      </code>
      group into this priority level. You may define other FlowSchemas that direct
      other requests to this priority level, if appropriate.
    </p>
  </li>
  <li>
    <p>
      The special
      <code>
        catch-all
      </code>
      priority level is used in combination with the special
      <code>
        catch-all
      </code>
      FlowSchema to make sure that every request gets some kind of
      classification. Typically you should not rely on this catch-all configuration,
      and should create your own catch-all FlowSchema and PriorityLevelConfiguration
      (or use the
      <code>
        global-default
      </code>
      configuration that is installed by default) as
      appropriate. To help catch configuration errors that miss classifying some
      requests, the mandatory
      <code>
        catch-all
      </code>
      priority level only allows one concurrency
      share and does not queue requests, making it relatively likely that traffic
      that only matches the
      <code>
        catch-all
      </code>
      FlowSchema will be rejected with an HTTP 429
      error.
    </p>
  </li>
</ul>
<h2 id="resources">
  Resources
</h2>
<p>
  The flow control API involves two kinds of resources.
  <a href="/docs/reference/generated/kubernetes-api/v1.18/#prioritylevelconfiguration-v1alpha1-flowcontrol-apiserver-k8s-io">
    PriorityLevelConfigurations
  </a>
  define the available isolation classes, the share of the available concurrency
  budget that each can handle, and allow for fine-tuning queuing behavior.
  <a href="/docs/reference/generated/kubernetes-api/v1.18/#flowschema-v1alpha1-flowcontrol-apiserver-k8s-io">
    FlowSchemas
  </a>
  are used to classify individual inbound requests, matching each to a single
  PriorityLevelConfiguration.
</p>
<h3 id="prioritylevelconfiguration">
  PriorityLevelConfiguration
</h3>
<p>
  A PriorityLevelConfiguration represents a single isolation class. Each
  PriorityLevelConfiguration has an independent limit on the number of outstanding
  requests, and limitations on the number of queued requests.
</p>
<p>
  Concurrency limits for PriorityLevelConfigurations are not specified in absolute
  number of requests, but rather in &ldquo;concurrency shares.&rdquo; The total concurrency
  limit for the API Server is distributed among the existing
  PriorityLevelConfigurations in proportion with these shares. This allows a
  cluster administrator to scale up or down the total amount of traffic to a
  server by restarting
  <code>
    kube-apiserver
  </code>
  with a different value for
  <code>
    --max-requests-inflight
  </code>
  (or
  <code>
    --max-mutating-requests-inflight
  </code>
  ), and all
  PriorityLevelConfigurations will see their maximum allowed concurrency go up (or
  down) by the same fraction.
</p>
<blockquote class="caution">
  <div>
    <strong>
      Caution:
    </strong>
    With the Priority and Fairness feature enabled, the total concurrency limit for
    the server is set to the sum of
    <code>
      --max-requests-inflight
    </code>
    and
    <code>
      --max-mutating-requests-inflight
    </code>
    . There is no longer any distinction made
    between mutating and non-mutating requests; if you want to treat them
    separately for a given resource, make separate FlowSchemas that match the
    mutating and non-mutating verbs respectively.
  </div>
</blockquote>
<p>
  When the volume of inbound requests assigned to a single
  PriorityLevelConfiguration is more than its permitted concurrency level, the
  <code>
    type
  </code>
  field of its specification determines what will happen to extra requests.
  A type of
  <code>
    Reject
  </code>
  means that excess traffic will immediately be rejected with
  an HTTP 429 (Too Many Requests) error. A type of
  <code>
    Queue
  </code>
  means that requests
  above the threshold will be queued, with the shuffle sharding and fair queuing techniques used
  to balance progress between request flows.
</p>
<p>
  The queuing configuration allows tuning the fair queuing algorithm for a
  priority level. Details of the algorithm can be read in the
  <a href="#what-s-next">
    enhancement
    proposal
  </a>
  , but in short:
</p>
<ul>
  <li>
    <p>
      Increasing
      <code>
        queues
      </code>
      reduces the rate of collisions between different flows, at
      the cost of increased memory usage. A value of 1 here effectively disables the
      fair-queuing logic, but still allows requests to be queued.
    </p>
  </li>
  <li>
    <p>
      Increasing
      <code>
        queueLengthLimit
      </code>
      allows larger bursts of traffic to be
      sustained without dropping any requests, at the cost of increased
      latency and memory usage.
    </p>
  </li>
  <li>
    <p>
      Changing
      <code>
        handSize
      </code>
      allows you to adjust the probability of collisions between
      different flows and the overall concurrency available to a single flow in an
      overload situation.
    </p>
    <blockquote class="note">
    <div>
    <strong>
      Note:
    </strong>
    A larger
    <code>
      handSize
    </code>
    makes it less likely for two individual flows to collide
  </li>
</ul>
<p>
(and therefore for one to be able to starve the other), but more likely that
a small number of flows can dominate the apiserver. A larger
<code>
  handSize
</code>
also
potentially increases the amount of latency that a single high-traffic flow
can cause. The maximum number of queued requests possible from a
single flow is
<code>
  handSize * queueLengthLimit
</code>
.
<p>
  Following is a table showing an interesting collection of shuffle
  sharding configurations, showing for each the probability that a
  given mouse (low-intensity flow) is squished by the elephants (high-intensity flows) for
  an illustrative collection of numbers of elephants. See
  <a href="https://play.golang.org/p/Gi0PLgVHiUg">
    https://play.golang.org/p/Gi0PLgVHiUg
  </a>
  , which computes this table.
</p>
<table>
  <caption style="display: none;">
    Example Shuffle Sharding Configurations
  </caption>
  <thead>
    <tr>
      <th>
        HandSize
      </th>
      <th>
        Queues
      </th>
      <th>
        1 elephant
      </th>
      <th>
        4 elephants
      </th>
      <th>
        16 elephants
      </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        12
      </td>
      <td>
        32
      </td>
      <td>
        4.428838398950118e-09
      </td>
      <td>
        0.11431348830099144
      </td>
      <td>
        0.9935089607656024
      </td>
    </tr>
    <tr>
      <td>
        10
      </td>
      <td>
        32
      </td>
      <td>
        1.550093439632541e-08
      </td>
      <td>
        0.0626479840223545
      </td>
      <td>
        0.9753101519027554
      </td>
    </tr>
    <tr>
      <td>
        10
      </td>
      <td>
        64
      </td>
      <td>
        6.601827268370426e-12
      </td>
      <td>
        0.00045571320990370776
      </td>
      <td>
        0.49999929150089345
      </td>
    </tr>
    <tr>
      <td>
        9
      </td>
      <td>
        64
      </td>
      <td>
        3.6310049976037345e-11
      </td>
      <td>
        0.00045501212304112273
      </td>
      <td>
        0.4282314876454858
      </td>
    </tr>
    <tr>
      <td>
        8
      </td>
      <td>
        64
      </td>
      <td>
        2.25929199850899e-10
      </td>
      <td>
        0.0004886697053040446
      </td>
      <td>
        0.35935114681123076
      </td>
    </tr>
    <tr>
      <td>
        8
      </td>
      <td>
        128
      </td>
      <td>
        6.994461389026097e-13
      </td>
      <td>
        3.4055790161620863e-06
      </td>
      <td>
        0.02746173137155063
      </td>
    </tr>
    <tr>
      <td>
        7
      </td>
      <td>
        128
      </td>
      <td>
        1.0579122850901972e-11
      </td>
      <td>
        6.960839379258192e-06
      </td>
      <td>
        0.02406157386340147
      </td>
    </tr>
    <tr>
      <td>
        7
      </td>
      <td>
        256
      </td>
      <td>
        7.597695465552631e-14
      </td>
      <td>
        6.728547142019406e-08
      </td>
      <td>
        0.0006709661542533682
      </td>
    </tr>
    <tr>
      <td>
        6
      </td>
      <td>
        256
      </td>
      <td>
        2.7134626662687968e-12
      </td>
      <td>
        2.9516464018476436e-07
      </td>
      <td>
        0.0008895654642000348
      </td>
    </tr>
    <tr>
      <td>
        6
      </td>
      <td>
        512
      </td>
      <td>
        4.116062922897309e-14
      </td>
      <td>
        4.982983350480894e-09
      </td>
      <td>
        2.26025764343413e-05
      </td>
    </tr>
    <tr>
      <td>
        6
      </td>
      <td>
        1024
      </td>
      <td>
        6.337324016514285e-16
      </td>
      <td>
        8.09060164312957e-11
      </td>
      <td>
        4.517408062903668e-07
      </td>
    </tr>
  </tbody>
</table>
<h3 id="flowschema">
  FlowSchema
</h3>
<p>
  A FlowSchema matches some inbound requests and assigns them to a
  priority level. Every inbound request is tested against every
  FlowSchema in turn, starting with those with numerically lowest &mdash;
  which we take to be the logically highest &mdash;
  <code>
    matchingPrecedence
  </code>
  and
  working onward.  The first match wins.
</p>
<blockquote class="caution">
  <div>
    <strong>
      Caution:
    </strong>
    Only the first matching FlowSchema for a given request matters. If multiple
    FlowSchemas match a single inbound request, it will be assigned based on the one
    with the highest
    <code>
      matchingPrecedence
    </code>
    . If multiple FlowSchemas with equal
    <code>
      matchingPrecedence
    </code>
    match the same request, the one with lexicographically
    smaller
    <code>
      name
    </code>
    will win, but it&rsquo;s better not to rely on this, and instead to
    ensure that no two FlowSchemas have the same
    <code>
      matchingPrecedence
    </code>
    .
  </div>
</blockquote>
<p>
  A FlowSchema matches a given request if at least one of its
  <code>
    rules
  </code>
  matches. A rule matches if at least one of its
  <code>
    subjects
  </code>
  <em>
    and
  </em>
  at least
  one of its
  <code>
    resourceRules
  </code>
  or
  <code>
    nonResourceRules
  </code>
  (depending on whether the
  incoming request is for a resource or non-resource URL) matches the request.
</p>
<p>
  For the
  <code>
    name
  </code>
  field in subjects, and the
  <code>
    verbs
  </code>
  ,
  <code>
    apiGroups
  </code>
  ,
  <code>
    resources
  </code>
  ,
  <code>
    namespaces
  </code>
  , and
  <code>
    nonResourceURLs
  </code>
  fields of resource and non-resource rules,
  the wildcard
  <code>
    *
  </code>
  may be specified to match all values for the given field,
  effectively removing it from consideration.
</p>
<p>
  A FlowSchema&rsquo;s
  <code>
    distinguisherMethod.type
  </code>
  determines how requests matching that
  schema will be separated into flows. It may be
  either
  <code>
    ByUser
  </code>
  , in which case one requesting user will not be able to starve
  other users of capacity, or
  <code>
    ByNamespace
  </code>
  , in which case requests for resources
  in one namespace will not be able to starve requests for resources in other
  namespaces of capacity, or it may be blank (or
  <code>
    distinguisherMethod
  </code>
  may be
  omitted entirely), in which case all requests matched by this FlowSchema will be
  considered part of a single flow. The correct choice for a given FlowSchema
  depends on the resource and your particular environment.
</p>
<h2 id="diagnostics">
  Diagnostics
</h2>
<p>
  Every HTTP response from an API server with the priority and fairness feature
  enabled has two extra headers:
  <code>
    X-Kubernetes-PF-FlowSchema-UID
  </code>
  and
  <code>
    X-Kubernetes-PF-PriorityLevel-UID
  </code>
  , noting the flow schema that matched the request
  and the priority level to which it was assigned, respectively. The API objects&rsquo;
  names are not included in these headers in case the requesting user does not
  have permission to view them, so when debugging you can use a command like
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get flowschemas -o custom-columns<span style="color:#666">=</span><span style="color:#b44">&#34;uid:{metadata.uid},name:{metadata.name}&#34;</span>
kubectl get prioritylevelconfigurations -o custom-columns<span style="color:#666">=</span><span style="color:#b44">&#34;uid:{metadata.uid},name:{metadata.name}&#34;</span></code></pre>
</div>
<p>
  to get a mapping of UIDs to names for both FlowSchemas and
  PriorityLevelConfigurations.
</p>
<h2 id="observability">
  Observability
</h2>
<p>
  When you enable the API Priority and Fairness feature, the kube-apiserver
  exports additional metrics. Monitoring these can help you determine whether your
  configuration is inappropriately throttling important traffic, or find
  poorly-behaved workloads that may be harming system health.
</p>
<ul>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_rejected_requests_total
      </code>
      counts requests that
      were rejected, grouped by the name of the assigned priority level,
      the name of the assigned FlowSchema, and the reason for rejection.
      The reason will be one of the following:
    </p>
    <ul>
      <li>
        <code>
          queue-full
        </code>
        , indicating that too many requests were already
        queued,
      </li>
      <li>
        <code>
          concurrency-limit
        </code>
        , indicating that the
        PriorityLevelConfiguration is configured to reject rather than
        queue excess requests, or
      </li>
      <li>
        <code>
          time-out
        </code>
        , indicating that the request was still in the queue
        when its queuing time limit expired.
      </li>
    </ul>
  </li>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_dispatched_requests_total
      </code>
      counts requests
      that began executing, grouped by the name of the assigned priority
      level and the name of the assigned FlowSchema.
    </p>
  </li>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_current_inqueue_requests
      </code>
      gives the
      instantaneous total number of queued (not executing) requests,
      grouped by priority level and FlowSchema.
    </p>
  </li>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_current_executing_requests
      </code>
      gives the instantaneous
      total number of executing requests, grouped by priority level and FlowSchema.
    </p>
  </li>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_request_queue_length_after_enqueue
      </code>
      gives a
      histogram of queue lengths for the queues, grouped by priority level
      and FlowSchema, as sampled by the enqueued requests.  Each request
      that gets queued contributes one sample to its histogram, reporting
      the length of the queue just after the request was added.  Note that
      this produces different statistics than an unbiased survey would.
    </p>
    <blockquote class="note">
    <div>
    <strong>
      Note:
    </strong>
    An outlier value in a histogram here means it is likely that a single flow
  </li>
</ul>
<p>
(i.e., requests by one user or for one namespace, depending on
configuration) is flooding the API server, and being throttled. By contrast,
if one priority level’s histogram shows that all queues for that priority
level are longer than those for other priority levels, it may be appropriate
to increase that PriorityLevelConfiguration’s concurrency shares.
<ul>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_request_concurrency_limit
      </code>
      gives the computed
      concurrency limit (based on the API server&rsquo;s total concurrency limit and PriorityLevelConfigurations&rsquo;
      concurrency shares) for each PriorityLevelConfiguration.
    </p>
  </li>
  <li>
    <p>
      <code>
        apiserver_flowcontrol_request_wait_duration_seconds
      </code>
      gives a histogram of how
      long requests spent queued, grouped by the FlowSchema that matched the
      request, the PriorityLevel to which it was assigned, and whether or not the
      request successfully executed.
    </p>
    <blockquote class="note">
    <div>
    <strong>
      Note:
    </strong>
    Since each FlowSchema always assigns requests to a single
  </li>
</ul>
<p>
PriorityLevelConfiguration, you can add the histograms for all the
FlowSchemas for one priority level to get the effective histogram for
requests assigned to that priority level.
<ul>
  <li>
    <code>
      apiserver_flowcontrol_request_execution_seconds
    </code>
    gives a histogram of how
    long requests took to actually execute, grouped by the FlowSchema that matched the
    request and the PriorityLevel to which it was assigned.
  </li>
</ul>
<h2 id="what-s-next">
  What&#39;s next
</h2>
<p>
  For background information on design details for API priority and fairness, see
  the
  <a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-api-machinery/20190228-priority-and-fairness.md">
    enhancement proposal
  </a>
  .
  You can make suggestions and feature requests via
  <a href="https://github.com/kubernetes/community/tree/master/sig-api-machinery">
    SIG API
    Machinery
  </a>
  .
</p>