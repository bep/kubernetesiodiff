<html><head></head><body>
<h1>
  Deployments
</h1>
<p>
  <a href="https://github.com/kubernetes/website/edit/master/content/en/docs/concepts/workloads/controllers/deployment.md" id="editPageButton" target="_blank">
    Edit This Page
  </a>
</p>
<h1>
  Deployments
</h1>
<p>
  A
  <em>
    Deployment
  </em>
  provides declarative updates for
  <a href="/docs/concepts/workloads/pods/pod/">
    Pods
  </a>
  and
  <a href="/docs/concepts/workloads/controllers/replicaset/">
    ReplicaSets
  </a>
  .
</p>
<p>
  You describe a
  <em>
    desired state
  </em>
  in a Deployment, and the Deployment
  <a class="glossary-tooltip" href="/docs/concepts/architecture/controller/" target="_blank">
    Controller
    <span class="tooltip-text">
      A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.
    </span>
  </a>
  changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.
</p>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    Do not manage ReplicaSets owned by a Deployment. Consider opening an issue in the main Kubernetes repository if your use case is not covered below.
  </div>
</blockquote>
<ul id="markdown-toc">
  <li>
    <a href="#use-case">
      Use Case
    </a>
  </li>
  <li>
    <a href="#creating-a-deployment">
      Creating a Deployment
    </a>
  </li>
  <li>
    <a href="#updating-a-deployment">
      Updating a Deployment
    </a>
  </li>
  <li>
    <a href="#rolling-back-a-deployment">
      Rolling Back a Deployment
    </a>
  </li>
  <li>
    <a href="#scaling-a-deployment">
      Scaling a Deployment
    </a>
  </li>
  <li>
    <a href="#pausing-and-resuming-a-deployment">
      Pausing and Resuming a Deployment
    </a>
  </li>
  <li>
    <a href="#deployment-status">
      Deployment status
    </a>
  </li>
  <li>
    <a href="#clean-up-policy">
      Clean up Policy
    </a>
  </li>
  <li>
    <a href="#canary-deployment">
      Canary Deployment
    </a>
  </li>
  <li>
    <a href="#writing-a-deployment-spec">
      Writing a Deployment Spec
    </a>
  </li>
</ul>
<h2 id="use-case">
  Use Case
</h2>
<p>
  The following are typical use cases for Deployments:
</p>
<ul>
  <li>
    <a href="#creating-a-deployment">
      Create a Deployment to rollout a ReplicaSet
    </a>
    . The ReplicaSet creates Pods in the background. Check the status of the rollout to see if it succeeds or not.
  </li>
  <li>
    <a href="#updating-a-deployment">
      Declare the new state of the Pods
    </a>
    by updating the PodTemplateSpec of the Deployment. A new ReplicaSet is created and the Deployment manages moving the Pods from the old ReplicaSet to the new one at a controlled rate. Each new ReplicaSet updates the revision of the Deployment.
  </li>
  <li>
    <a href="#rolling-back-a-deployment">
      Rollback to an earlier Deployment revision
    </a>
    if the current state of the Deployment is not stable. Each rollback updates the revision of the Deployment.
  </li>
  <li>
    <a href="#scaling-a-deployment">
      Scale up the Deployment to facilitate more load
    </a>
    .
  </li>
  <li>
    <a href="#pausing-and-resuming-a-deployment">
      Pause the Deployment
    </a>
    to apply multiple fixes to its PodTemplateSpec and then resume it to start a new rollout.
  </li>
  <li>
    <a href="#deployment-status">
      Use the status of the Deployment
    </a>
    as an indicator that a rollout has stuck.
  </li>
  <li>
    <a href="#clean-up-policy">
      Clean up older ReplicaSets
    </a>
    that you don’t need anymore.
  </li>
</ul>
<h2 id="creating-a-deployment">
  Creating a Deployment
</h2>
<p>
  The following is an example of a Deployment. It creates a ReplicaSet to bring up three
  <code>
    nginx
  </code>
  Pods:
</p>
<table class="includecode" id="controllers-nginx-deployment-yaml">
  <thead>
    <tr>
      <th>
        <a href="https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/controllers/nginx-deployment.yaml" download="controllers/nginx-deployment.yaml">
          <code>
            controllers/nginx-deployment.yaml
          </code>
        </a>
        <img src="/dir2/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode(&#39;controllers-nginx-deployment-yaml&#39;)" title="Copy controllers/nginx-deployment.yaml to clipboard"/>
      </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <div class="highlight">
          <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#a2f;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#a2f;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#a2f;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#a2f;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx-deployment<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#a2f;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a2f;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#a2f;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#a2f;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">3</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#a2f;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a2f;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#a2f;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#a2f;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a2f;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#a2f;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#a2f;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a2f;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#a2f;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#a2f;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#a2f;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx:<span style="color:#666">1.14.2</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#a2f;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#a2f;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span></code></pre>
        </div>
      </td>
    </tr>
  </tbody>
</table>
<p>
  In this example:
</p>
<ul>
  <li>
    A Deployment named
    <code>
      nginx-deployment
    </code>
    is created, indicated by the
    <code>
      .metadata.name
    </code>
    field.
  </li>
  <li>
    The Deployment creates three replicated Pods, indicated by the
    <code>
      replicas
    </code>
    field.
  </li>
  <li>
    The
    <code data-diff="">
      selector
    </code>
    field defines how the Deployment finds which Pods to manage.
    In this case, you simply select a label that is defined in the Pod template (
    <code>
      app: nginx
    </code>
    ).
    However, more sophisticated selection rules are possible,
    as long as the Pod template itself satisfies the rule.
    <blockquote class="note">
    <div>
    <strong>
      Note:
    </strong>
    The
    <code>
      matchLabels
    </code>
    field is a map of {key,value} pairs. A single {key,value} in the
    <code>
      matchLabels
    </code>
    map
  </div></blockquote></li>
</ul>
<p>
is equivalent to an element of
<code>
  matchExpressions
</code>
, whose key field is “key” the operator is “In”,
and the values array contains only “value”.
All of the requirements, from both
<code>
  matchLabels
</code>
and
<code>
  matchExpressions
</code>
, must be satisfied in order to match.
</p><ul>
  <li>
    <p>
      The
      <code>
        template
      </code>
      field contains the following sub-fields:
    </p>
    <ul>
      <li>
        The Pods are labeled
        <code>
          app: nginx
        </code>
        using the
        <code>
          labels
        </code>
        field.
      </li>
      <li>
        The Pod template’s specification, or
        <code>
          .template.spec
        </code>
        field, indicates that
        the Pods run one container,
        <code>
          nginx
        </code>
        , which runs the
        <code>
          nginx
        </code>
        <a href="https://hub.docker.com/">
          Docker Hub
        </a>
        image at version 1.14.2.
      </li>
      <li>
        Create one container and name it
        <code>
          nginx
        </code>
        using the
        <code>
          name
        </code>
        field.
      </li>
    </ul>
    <p>
      Follow the steps given below to create the above Deployment:
    </p>
    <p>
      Before you begin, make sure your Kubernetes cluster is up and running.
    </p>
    <ol>
      <li>
        <p>
          Create the Deployment by running the following command:
        </p>
        <blockquote class="note">
      </blockquote></li>
    </ol>
    <div>
    <strong>
      Note:
    </strong>
    You may specify the
    <code>
      --record
    </code>
    flag to write the command executed in the resource annotation
    <code>
      kubernetes.io/change-cause
    </code>
    . It is useful for future introspection.
  </div></li>
</ul>
<p>
For example, to see the commands executed in each Deployment revision.</p><pre><code>```shell
kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
```</code></pre>
<ol start="2">
  <li>
    <p>
      Run
      <code>
        kubectl get deployments
      </code>
      to check if the Deployment was created. If the Deployment is still being created, the output is similar to the following:
      <code>
        shell NAME               READY   UP-TO-DATE   AVAILABLE   AGE nginx-deployment   0/3     0            0           1s
      </code>
      When you inspect the Deployments in your cluster, the following fields are displayed:
    </p>
    <ul>
      <li>
        <code>
          NAME
        </code>
        lists the names of the Deployments in the cluster.
      </li>
      <li>
        <code>
          DESIRED
        </code>
        displays the desired number of
        <em>
          replicas
        </em>
        of the application, which you define when you create the Deployment. This is the
        <em>
          desired state
        </em>
        .
      </li>
      <li>
        <code>
          CURRENT
        </code>
        displays how many replicas are currently running.
      </li>
      <li>
        <code>
          UP-TO-DATE
        </code>
        displays the number of replicas that have been updated to achieve the desired state.
      </li>
      <li>
        <code>
          AVAILABLE
        </code>
        displays how many replicas of the application are available to your users.
      </li>
      <li>
        <code>
          AGE
        </code>
        displays the amount of time that the application has been running.
      </li>
    </ul>
  </li>
</ol><pre><code>Notice how the number of desired replicas is 3 according to `.spec.replicas` field.</code></pre>
<ol start="3">
  <li>
    <p>
      To see the Deployment rollout status, run
      <code>
        kubectl rollout status deployment.v1.apps/nginx-deployment
      </code>
      . The output is similar to this:
      <code>
        shell Waiting for rollout to finish: 2 out of 3 new replicas have been updated... deployment.apps/nginx-deployment successfully rolled out
      </code>
    </p>
  </li>
  <li>
    <p>
      Run the
      <code>
        kubectl get deployments
      </code>
      again a few seconds later. The output is similar to this:
      <code>
        shell NAME               READY   UP-TO-DATE   AVAILABLE   AGE nginx-deployment   3/3     3            3           18s
      </code>
      Notice that the Deployment has created all three replicas, and all replicas are up-to-date (they contain the latest Pod template) and available.
    </p>
  </li>
  <li>
    <p>
      To see the ReplicaSet (
      <code>
        rs
      </code>
      ) created by the Deployment, run
      <code>
        kubectl get rs
      </code>
      . The output is similar to this:
      <code>
        shell NAME                          DESIRED   CURRENT   READY   AGE nginx-deployment-75675f5897   3         3         3       18s
      </code>
      Notice that the name of the ReplicaSet is always formatted as
      <code>
        [DEPLOYMENT-NAME]-[RANDOM-STRING]
      </code>
      . The random string is
      randomly generated and uses the pod-template-hash as a seed.
    </p>
  </li>
  <li>
    <p>
      To see the labels automatically generated for each Pod, run
      <code>
        kubectl get pods --show-labels
      </code>
      . The following output is returned:
      <code>
        shell NAME                                READY     STATUS    RESTARTS   AGE       LABELS nginx-deployment-75675f5897-7ci7o   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453 nginx-deployment-75675f5897-kzszj   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453 nginx-deployment-75675f5897-qqcnn   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
      </code>
      The created ReplicaSet ensures that there are three
      <code>
        nginx
      </code>
      Pods.
    </p>
  </li>
</ol>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    You must specify an appropriate selector and Pod template labels in a Deployment (in this case,
    <code>
      app: nginx
    </code>
    ). Do not overlap labels or selectors with other controllers (including other Deployments and StatefulSets). Kubernetes doesn’t stop you from overlapping, and if multiple controllers have overlapping selectors those controllers might conflict and behave unexpectedly.
  </div>
</blockquote>
<h3 id="pod-template-hash-label">
  Pod-template-hash label
</h3>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    Do not change this label.
  </div>
</blockquote>
<p>
  The
  <code>
    pod-template-hash
  </code>
  label is added by the Deployment controller to every ReplicaSet that a Deployment creates or adopts.
</p>
<p>
  This label ensures that child ReplicaSets of a Deployment do not overlap. It is generated by hashing the
  <code>
    PodTemplate
  </code>
  of the ReplicaSet and using the resulting hash as the label value that is added to the ReplicaSet selector, Pod template labels,
  and in any existing Pods that the ReplicaSet might have.
</p>
<h2 id="updating-a-deployment">
  Updating a Deployment
</h2>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    A Deployment’s rollout is triggered if and only if the Deployment’s Pod template (that is,
    <code>
      .spec.template
    </code>
    )
    is changed, for example if the labels or container images of the template are updated. Other updates, such as scaling the Deployment, do not trigger a rollout.
  </div>
</blockquote>
<p>
  Follow the steps given below to update your Deployment:
</p>
<ol>
  <li>
    <p>
      Let’s update the nginx Pods to use the
      <code>
        nginx:1.16.1
      </code>
      image instead of the
      <code>
        nginx:1.14.2
      </code>
      image.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl --record deployment.apps/nginx-deployment <span style="color:#a2f">set</span> image deployment.v1.apps/nginx-deployment <span style="color:#b8860b">nginx</span><span style="color:#666">=</span>nginx:1.16.1</code></pre>
    </div>
    <p>
      or simply use the following command:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">set</span> image deployment/nginx-deployment <span style="color:#b8860b">nginx</span><span style="color:#666">=</span>nginx:1.16.1 --record</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment image updated</code></pre>
    <p>
      Alternatively, you can
      <code>
        edit
      </code>
      the Deployment and change
      <code>
        .spec.template.spec.containers[0].image
      </code>
      from
      <code>
        nginx:1.14.2
      </code>
      to
      <code>
        nginx:1.16.1
      </code>
      :
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment edited</code></pre>
  </li>
  <li>
    <p>
      To see the rollout status, run:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout status deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...</code></pre>
    <p>
      or
    </p>
    <pre><code>deployment.apps/nginx-deployment successfully rolled out</code></pre>
  </li>
</ol>
<p>
  Get more details on your updated Deployment:
</p>
<ul>
  <li>
    <p>
      After the rollout succeeds, you can view the Deployment by running
      <code>
        kubectl get deployments
      </code>
      .
      The output is similar to this:
    </p>
    <pre><code>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           36s</code></pre>
  </li>
  <li>
    <p>
      Run
      <code>
        kubectl get rs
      </code>
      to see that the Deployment updated the Pods by creating a new ReplicaSet and scaling it
      up to 3 replicas, as well as scaling down the old ReplicaSet to 0 replicas.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       6s
nginx-deployment-2035384211   0         0         0       36s</code></pre>
  </li>
  <li>
    <p>
      Running
      <code>
        get pods
      </code>
      should now show only the new Pods:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1564180365-khku8   1/1       Running   0          14s
nginx-deployment-1564180365-nacti   1/1       Running   0          14s
nginx-deployment-1564180365-z9gth   1/1       Running   0          14s</code></pre>
    <p>
      Next time you want to update these Pods, you only need to update the Deployment’s Pod template again.
    </p>
    <p>
      Deployment ensures that only a certain number of Pods are down while they are being updated. By default,
      it ensures that at least 75% of the desired number of Pods are up (25% max unavailable).
    </p>
    <p>
      Deployment also ensures that only a certain number of Pods are created above the desired number of Pods.
      By default, it ensures that at most 125% of the desired number of Pods are up (25% max surge).
    </p>
    <p>
      For example, if you look at the above Deployment closely, you will see that it first created a new Pod,
      then deleted some old Pods, and created new ones. It does not kill old Pods until a sufficient number of
      new Pods have come up, and does not create new Pods until a sufficient number of old Pods have been killed.
      It makes sure that at least 2 Pods are available and that at max 4 Pods in total are available.
    </p>
  </li>
  <li>
    <p>
      Get details of your Deployment:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe deployments</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Thu, 30 Nov 2017 10:56:25 +0000
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=2
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
   Containers:
    nginx:
      Image:        nginx:1.16.1
      Port:         80/TCP
      Environment:  &lt;none&gt;
      Mounts:       &lt;none&gt;
    Volumes:        &lt;none&gt;
  Conditions:
    Type           Status  Reason
    ----           ------  ------
    Available      True    MinimumReplicasAvailable
    Progressing    True    NewReplicaSetAvailable
  OldReplicaSets:  &lt;none&gt;
  NewReplicaSet:   nginx-deployment-1564180365 (3/3 replicas created)
  Events:
    Type    Reason             Age   From                   Message
    ----    ------             ----  ----                   -------
    Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-deployment-2035384211 to 3
    Normal  ScalingReplicaSet  24s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 1
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 2
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 2
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 1
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 3
    Normal  ScalingReplicaSet  14s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 0</code></pre>
    <p>
      Here you see that when you first created the Deployment, it created a ReplicaSet (nginx-deployment-2035384211)
      and scaled it up to 3 replicas directly. When you updated the Deployment, it created a new ReplicaSet
      (nginx-deployment-1564180365) and scaled it up to 1 and then scaled down the old ReplicaSet to 2, so that at
      least 2 Pods were available and at most 4 Pods were created at all times. It then continued scaling up and down
      the new and the old ReplicaSet, with the same rolling update strategy. Finally, you’ll have 3 available replicas
      in the new ReplicaSet, and the old ReplicaSet is scaled down to 0.
    </p>
  </li>
</ul>
<h3 id="rollover-aka-multiple-updates-in-flight">
  Rollover (aka multiple updates in-flight)
</h3>
<p>
  Each time a new Deployment is observed by the Deployment controller, a ReplicaSet is created to bring up
  the desired Pods. If the Deployment is updated, the existing ReplicaSet that controls Pods whose labels
  match
  <code>
    .spec.selector
  </code>
  but whose template does not match
  <code>
    .spec.template
  </code>
  are scaled down. Eventually, the new
  ReplicaSet is scaled to
  <code>
    .spec.replicas
  </code>
  and all old ReplicaSets is scaled to 0.
</p>
<p>
  If you update a Deployment while an existing rollout is in progress, the Deployment creates a new ReplicaSet
  as per the update and start scaling that up, and rolls over the ReplicaSet that it was scaling up previously
  – it will add it to its list of old ReplicaSets and start scaling it down.
</p>
<p>
  For example, suppose you create a Deployment to create 5 replicas of
  <code>
    nginx:1.14.2
  </code>
  ,
  but then update the Deployment to create 5 replicas of
  <code>
    nginx:1.16.1
  </code>
  , when only 3
  replicas of
  <code>
    nginx:1.14.2
  </code>
  had been created. In that case, the Deployment immediately starts
  killing the 3
  <code>
    nginx:1.14.2
  </code>
  Pods that it had created, and starts creating
  <code>
    nginx:1.16.1
  </code>
  Pods. It does not wait for the 5 replicas of
  <code>
    nginx:1.14.2
  </code>
  to be created
  before changing course.
</p>
<h3 id="label-selector-updates">
  Label selector updates
</h3>
<p>
  It is generally discouraged to make label selector updates and it is suggested to plan your selectors up front.
  In any case, if you need to perform a label selector update, exercise great caution and make sure you have grasped
  all of the implications.
</p>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    In API version
    <code>
      apps/v1
    </code>
    , a Deployment’s label selector is immutable after it gets created.
  </div>
</blockquote>
<ul>
  <li>
    Selector additions require the Pod template labels in the Deployment spec to be updated with the new label too,
    otherwise a validation error is returned. This change is a non-overlapping one, meaning that the new selector does
    not select ReplicaSets and Pods created with the old selector, resulting in orphaning all old ReplicaSets and
    creating a new ReplicaSet.
  </li>
  <li>
    Selector updates changes the existing value in a selector key – result in the same behavior as additions.
  </li>
  <li>
    Selector removals removes an existing key from the Deployment selector – do not require any changes in the
    Pod template labels. Existing ReplicaSets are not orphaned, and a new ReplicaSet is not created, but note that the
    removed label still exists in any existing Pods and ReplicaSets.
  </li>
</ul>
<h2 id="rolling-back-a-deployment">
  Rolling Back a Deployment
</h2>
<p>
  Sometimes, you may want to rollback a Deployment; for example, when the Deployment is not stable, such as crash looping.
  By default, all of the Deployment’s rollout history is kept in the system so that you can rollback anytime you want
  (you can change that by modifying revision history limit).
</p>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    A Deployment’s revision is created when a Deployment’s rollout is triggered. This means that the
    new revision is created if and only if the Deployment’s Pod template (
    <code>
      .spec.template
    </code>
    ) is changed,
    for example if you update the labels or container images of the template. Other updates, such as scaling the Deployment,
    do not create a Deployment revision, so that you can facilitate simultaneous manual- or auto-scaling.
    This means that when you roll back to an earlier revision, only the Deployment’s Pod template part is
    rolled back.
  </div>
</blockquote>
<ul>
  <li>
    <p>
      Suppose that you made a typo while updating the Deployment, by putting the image name as
      <code>
        nginx:1.161
      </code>
      instead of
      <code>
        nginx:1.16.1
      </code>
      :
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">set</span> image deployment.v1.apps/nginx-deployment <span style="color:#b8860b">nginx</span><span style="color:#666">=</span>nginx:1.161 --record<span style="color:#666">=</span><span style="color:#a2f">true</span></code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment image updated</code></pre>
  </li>
  <li>
    <p>
      The rollout gets stuck. You can verify it by checking the rollout status:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout status deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>Waiting for rollout to finish: 1 out of 3 new replicas have been updated...</code></pre>
  </li>
  <li>
    <p>
      Press Ctrl-C to stop the above rollout status watch. For more information on stuck rollouts,
      <a href="#deployment-status">
        read more here
      </a>
      .
    </p>
  </li>
  <li>
    <p>
      You see that the number of old replicas (
      <code>
        nginx-deployment-1564180365
      </code>
      and
      <code>
        nginx-deployment-2035384211
      </code>
      ) is 2, and new replicas (nginx-deployment-3066724191) is 1.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       25s
nginx-deployment-2035384211   0         0         0       36s
nginx-deployment-3066724191   1         1         0       6s</code></pre>
  </li>
  <li>
    <p>
      Looking at the Pods created, you see that 1 Pod created by new ReplicaSet is stuck in an image pull loop.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME                                READY     STATUS             RESTARTS   AGE
nginx-deployment-1564180365-70iae   1/1       Running            0          25s
nginx-deployment-1564180365-jbqqo   1/1       Running            0          25s
nginx-deployment-1564180365-hysrc   1/1       Running            0          25s
nginx-deployment-3066724191-08mng   0/1       ImagePullBackOff   0          6s</code></pre>
    <blockquote class="note">
    <div>
    <strong>
      Note:
    </strong>
    The Deployment controller stops the bad rollout automatically, and stops scaling up the new
  </div></blockquote></li>
</ul>
<p>
ReplicaSet. This depends on the rollingUpdate parameters (
<code>
  maxUnavailable
</code>
specifically) that you have specified.
Kubernetes by default sets the value to 25%.
</p><ul>
  <li>
    <p>
      Get the description of the Deployment:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>Name:           nginx-deployment
Namespace:      default
CreationTimestamp:  Tue, 15 Mar 2016 14:48:04 -0700
Labels:         app=nginx
Selector:       app=nginx
Replicas:       3 desired | 1 updated | 4 total | 3 available | 1 unavailable
StrategyType:       RollingUpdate
MinReadySeconds:    0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.161
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    ReplicaSetUpdated
OldReplicaSets:     nginx-deployment-1564180365 (3/3 replicas created)
NewReplicaSet:      nginx-deployment-3066724191 (1/1 replicas created)
Events:
  FirstSeen LastSeen    Count   From                    SubObjectPath   Type        Reason              Message
  --------- --------    -----   ----                    -------------   --------    ------              -------
  1m        1m          1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-2035384211 to 3
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 1
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 2
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 2
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 1
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 3
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 0
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-3066724191 to 1</code></pre>
    <p>
      To fix this, you need to rollback to a previous revision of Deployment that is stable.
    </p>
  </li>
</ul>
<h3 id="checking-rollout-history-of-a-deployment">
  Checking Rollout History of a Deployment
</h3>
<p>
  Follow the steps given below to check the rollout history:
</p>
<ol>
  <li>
    <p>
      First, check the revisions of this Deployment:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout <span style="color:#a2f">history</span> deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployments &#34;nginx-deployment&#34;
REVISION    CHANGE-CAUSE
1           kubectl apply --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true
2           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1 --record=true
3           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.161 --record=true</code></pre>
    <p>
      <code>
        CHANGE-CAUSE
      </code>
      is copied from the Deployment annotation
      <code>
        kubernetes.io/change-cause
      </code>
      to its revisions upon creation. You can specify the
      <code>
        CHANGE-CAUSE
      </code>
      message by:
    </p>
    <ul>
      <li>
        Annotating the Deployment with
        <code>
          kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause=&#34;image updated to 1.16.1&#34;
        </code>
      </li>
      <li>
        Append the
        <code>
          --record
        </code>
        flag to save the
        <code>
          kubectl
        </code>
        command that is making changes to the resource.
      </li>
      <li>
        Manually editing the manifest of the resource.
      </li>
    </ul>
  </li>
  <li>
    <p>
      To see the details of each revision, run:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout <span style="color:#a2f">history</span> deployment.v1.apps/nginx-deployment --revision<span style="color:#666">=</span><span style="color:#666">2</span></code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployments &#34;nginx-deployment&#34; revision 2
  Labels:       app=nginx
          pod-template-hash=1159050644
  Annotations:  kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1 --record=true
  Containers:
   nginx:
    Image:      nginx:1.16.1
    Port:       80/TCP
     QoS Tier:
        cpu:      BestEffort
        memory:   BestEffort
    Environment Variables:      &lt;none&gt;
  No volumes.</code></pre>
  </li>
</ol>
<h3 id="rolling-back-to-a-previous-revision">
  Rolling Back to a Previous Revision
</h3>
<p>
  Follow the steps given below to rollback the Deployment from the current version to the previous version, which is version 2.
</p>
<ol>
  <li>
    <p>
      Now you’ve decided to undo the current rollout and rollback to the previous revision:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout undo deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment</code></pre>
    <p>
      Alternatively, you can rollback to a specific revision by specifying it with
      <code>
        --to-revision
      </code>
      :
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision<span style="color:#666">=</span><span style="color:#666">2</span></code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment</code></pre>
    <p>
      For more details about rollout related commands, read
      <a href="/docs/reference/generated/kubectl/kubectl-commands#rollout">
        <code>
          kubectl rollout
        </code>
      </a>
      .
    </p>
    <p>
      The Deployment is now rolled back to a previous stable revision. As you can see, a
      <code>
        DeploymentRollback
      </code>
      event
      for rolling back to revision 2 is generated from Deployment controller.
    </p>
  </li>
  <li>
    <p>
      Check if the rollback was successful and the Deployment is running as expected, run:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deployment nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           30m</code></pre>
  </li>
  <li>
    <p>
      Get the description of the Deployment:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe deployment nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Sun, 02 Sep 2018 18:17:55 -0500
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=4
                        kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1 --record=true
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.16.1
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   nginx-deployment-c4747d96c (3/3 replicas created)
Events:
  Type    Reason              Age   From                   Message
  ----    ------              ----  ----                   -------
  Normal  ScalingReplicaSet   12m   deployment-controller  Scaled up replica set nginx-deployment-75675f5897 to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 0
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-595696685f to 1
  Normal  DeploymentRollback  15s   deployment-controller  Rolled back deployment &#34;nginx-deployment&#34; to revision 2
  Normal  ScalingReplicaSet   15s   deployment-controller  Scaled down replica set nginx-deployment-595696685f to 0</code></pre>
  </li>
</ol>
<h2 id="scaling-a-deployment">
  Scaling a Deployment
</h2>
<p>
  You can scale a Deployment by using the following command:
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl scale deployment.v1.apps/nginx-deployment --replicas<span style="color:#666">=</span><span style="color:#666">10</span></code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>deployment.apps/nginx-deployment scaled</code></pre>
<p>
  Assuming
  <a href="/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">
    horizontal Pod autoscaling
  </a>
  is enabled
  in your cluster, you can setup an autoscaler for your Deployment and choose the minimum and maximum number of
  Pods you want to run based on the CPU utilization of your existing Pods.
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl autoscale deployment.v1.apps/nginx-deployment --min<span style="color:#666">=</span><span style="color:#666">10</span> --max<span style="color:#666">=</span><span style="color:#666">15</span> --cpu-percent<span style="color:#666">=</span><span style="color:#666">80</span></code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>deployment.apps/nginx-deployment scaled</code></pre>
<h3 id="proportional-scaling">
  Proportional scaling
</h3>
<p>
  RollingUpdate Deployments support running multiple versions of an application at the same time. When you
  or an autoscaler scales a RollingUpdate Deployment that is in the middle of a rollout (either in progress
  or paused), the Deployment controller balances the additional replicas in the existing active
  ReplicaSets (ReplicaSets with Pods) in order to mitigate risk. This is called
  <em>
    proportional scaling
  </em>
  .
</p>
<p>
  For example, you are running a Deployment with 10 replicas,
  <a href="#max-surge">
    maxSurge
  </a>
  =3, and
  <a href="#max-unavailable">
    maxUnavailable
  </a>
  =2.
</p>
<ul>
  <li>
    <p>
      Ensure that the 10 replicas in your Deployment are running.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deploy</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     10        10        10           10          50s</code></pre>
  </li>
  <li>
    <p>
      You update to a new image which happens to be unresolvable from inside the cluster.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">set</span> image deployment.v1.apps/nginx-deployment <span style="color:#b8860b">nginx</span><span style="color:#666">=</span>nginx:sometag</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment image updated</code></pre>
  </li>
  <li>
    <p>
      The image update starts a new rollout with ReplicaSet nginx-deployment-1989198191, but it’s blocked due to the
      <code>
        maxUnavailable
      </code>
      requirement that you mentioned above. Check out the rollout status:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
    </div>
    <pre><code>The output is similar to this:</code></pre>
    <pre><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   5         5         0         9s
nginx-deployment-618515232    8         8         8         1m</code></pre>
  </li>
  <li>
    <p>
      Then a new scaling request for the Deployment comes along. The autoscaler increments the Deployment replicas
      to 15. The Deployment controller needs to decide where to add these new 5 replicas. If you weren’t using
      proportional scaling, all 5 of them would be added in the new ReplicaSet. With proportional scaling, you
      spread the additional replicas across all ReplicaSets. Bigger proportions go to the ReplicaSets with the
      most replicas and lower proportions go to ReplicaSets with less replicas. Any leftovers are added to the
      ReplicaSet with the most replicas. ReplicaSets with zero replicas are not scaled up.
    </p>
  </li>
</ul>
<p>
  In our example above, 3 replicas are added to the old ReplicaSet and 2 replicas are added to the
  new ReplicaSet. The rollout process should eventually move all replicas to the new ReplicaSet, assuming
  the new replicas become healthy. To confirm this, run:
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deploy</code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     15        18        7            8           7m</code></pre>
<p>
  The rollout status confirms how the replicas were added to each ReplicaSet.
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   7         7         0         7m
nginx-deployment-618515232    11        11        11        7m</code></pre>
<h2 id="pausing-and-resuming-a-deployment">
  Pausing and Resuming a Deployment
</h2>
<p>
  You can pause a Deployment before triggering one or more updates and then resume it. This allows you to
  apply multiple fixes in between pausing and resuming without triggering unnecessary rollouts.
</p>
<ul>
  <li>
    <p>
      For example, with a Deployment that was just created:
      Get the Deployment details:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deploy</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     3         3         3            3           1m</code></pre>
    <p>
      Get the rollout status:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         1m</code></pre>
  </li>
  <li>
    <p>
      Pause by running the following command:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout pause deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment paused</code></pre>
  </li>
  <li>
    <p>
      Then update the image of the Deployment:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">set</span> image deployment.v1.apps/nginx-deployment <span style="color:#b8860b">nginx</span><span style="color:#666">=</span>nginx:1.16.1</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment image updated</code></pre>
  </li>
  <li>
    <p>
      Notice that no new rollout started:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout <span style="color:#a2f">history</span> deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployments &#34;nginx&#34;
REVISION  CHANGE-CAUSE
1   &lt;none&gt;</code></pre>
  </li>
  <li>
    <p>
      Get the rollout status to ensure that the Deployment is updates successfully:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         2m</code></pre>
  </li>
  <li>
    <p>
      You can make as many updates as you wish, for example, update the resources that will be used:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">set</span> resources deployment.v1.apps/nginx-deployment -c<span style="color:#666">=</span>nginx --limits<span style="color:#666">=</span><span style="color:#b8860b">cpu</span><span style="color:#666">=</span>200m,memory<span style="color:#666">=</span>512Mi</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment resource requirements updated</code></pre>
    <p>
      The initial state of the Deployment prior to pausing it will continue its function, but new updates to
      the Deployment will not have any effect as long as the Deployment is paused.
    </p>
  </li>
  <li>
    <p>
      Eventually, resume the Deployment and observe a new ReplicaSet coming up with all the new updates:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout resume deployment.v1.apps/nginx-deployment</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>deployment.apps/nginx-deployment resumed</code></pre>
  </li>
  <li>
    <p>
      Watch the status of the rollout until it’s done.
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs -w</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   2         2         2         2m
nginx-3926361531   2         2         0         6s
nginx-3926361531   2         2         1         18s
nginx-2142116321   1         2         2         2m
nginx-2142116321   1         2         2         2m
nginx-3926361531   3         2         1         18s
nginx-3926361531   3         2         1         18s
nginx-2142116321   1         1         1         2m
nginx-3926361531   3         3         1         18s
nginx-3926361531   3         3         2         19s
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         20s</code></pre>
  </li>
  <li>
    <p>
      Get the status of the latest rollout:
    </p>
    <div class="highlight">
      <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get rs</code></pre>
    </div>
    <p>
      The output is similar to this:
    </p>
    <pre><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         28s</code></pre>
  </li>
</ul>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    You cannot rollback a paused Deployment until you resume it.
  </div>
</blockquote>
<h2 id="deployment-status">
  Deployment status
</h2>
<p>
  A Deployment enters various states during its lifecycle. It can be
  <a href="#progressing-deployment">
    progressing
  </a>
  while
  rolling out a new ReplicaSet, it can be
  <a href="#complete-deployment">
    complete
  </a>
  , or it can
  <a href="#failed-deployment">
    fail to progress
  </a>
  .
</p>
<h3 id="progressing-deployment">
  Progressing Deployment
</h3>
<p>
  Kubernetes marks a Deployment as
  <em>
    progressing
  </em>
  when one of the following tasks is performed:
</p>
<ul>
  <li>
    The Deployment creates a new ReplicaSet.
  </li>
  <li>
    The Deployment is scaling up its newest ReplicaSet.
  </li>
  <li>
    The Deployment is scaling down its older ReplicaSet(s).
  </li>
  <li>
    New Pods become ready or available (ready for at least
    <a href="#min-ready-seconds">
      MinReadySeconds
    </a>
    ).
  </li>
</ul>
<p>
  You can monitor the progress for a Deployment by using
  <code>
    kubectl rollout status
  </code>
  .
</p>
<h3 id="complete-deployment">
  Complete Deployment
</h3>
<p>
  Kubernetes marks a Deployment as
  <em>
    complete
  </em>
  when it has the following characteristics:
</p>
<ul>
  <li>
    All of the replicas associated with the Deployment have been updated to the latest version you’ve specified, meaning any
    updates you’ve requested have been completed.
  </li>
  <li>
    All of the replicas associated with the Deployment are available.
  </li>
  <li>
    No old replicas for the Deployment are running.
  </li>
</ul>
<p>
  You can check if a Deployment has completed by using
  <code>
    kubectl rollout status
  </code>
  . If the rollout completed
  successfully,
  <code>
    kubectl rollout status
  </code>
  returns a zero exit code.
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout status deployment.v1.apps/nginx-deployment</code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>Waiting for rollout to finish: 2 of 3 updated replicas are available...
deployment.apps/nginx-deployment successfully rolled out
$ echo $?
0</code></pre>
<h3 id="failed-deployment">
  Failed Deployment
</h3>
<p>
  Your Deployment may get stuck trying to deploy its newest ReplicaSet without ever completing. This can occur
  due to some of the following factors:
</p>
<ul>
  <li>
    Insufficient quota
  </li>
  <li>
    Readiness probe failures
  </li>
  <li>
    Image pull errors
  </li>
  <li>
    Insufficient permissions
  </li>
  <li>
    Limit ranges
  </li>
  <li>
    Application runtime misconfiguration
  </li>
</ul>
<p>
  One way you can detect this condition is to specify a deadline parameter in your Deployment spec:
  (
  <a href="#progress-deadline-seconds">
    <code>
      .spec.progressDeadlineSeconds
    </code>
  </a>
  ).
  <code>
    .spec.progressDeadlineSeconds
  </code>
  denotes the
  number of seconds the Deployment controller waits before indicating (in the Deployment status) that the
  Deployment progress has stalled.
</p>
<p>
  The following
  <code>
    kubectl
  </code>
  command sets the spec with
  <code>
    progressDeadlineSeconds
  </code>
  to make the controller report
  lack of progress for a Deployment after 10 minutes:
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl patch deployment.v1.apps/nginx-deployment -p <span style="color:#b44">&#39;{&#34;spec&#34;:{&#34;progressDeadlineSeconds&#34;:600}}&#39;</span></code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>deployment.apps/nginx-deployment patched</code></pre>
<p>
  Once the deadline has been exceeded, the Deployment controller adds a DeploymentCondition with the following
  attributes to the Deployment’s
  <code>
    .status.conditions
  </code>
  :
</p>
<ul>
  <li>
    Type=Progressing
  </li>
  <li>
    Status=False
  </li>
  <li>
    Reason=ProgressDeadlineExceeded
  </li>
</ul>
<p>
  See the
  <a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#typical-status-properties">
    Kubernetes API conventions
  </a>
  for more information on status conditions.
</p>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    Kubernetes takes no action on a stalled Deployment other than to report a status condition with
    <code>
      Reason=ProgressDeadlineExceeded
    </code>
    . Higher level orchestrators can take advantage of it and act accordingly, for
    example, rollback the Deployment to its previous version.
  </div>
</blockquote>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    If you pause a Deployment, Kubernetes does not check progress against your specified deadline. You can
    safely pause a Deployment in the middle of a rollout and resume without triggering the condition for exceeding the
    deadline.
  </div>
</blockquote>
<p>
  You may experience transient errors with your Deployments, either due to a low timeout that you have set or
  due to any other kind of error that can be treated as transient. For example, let’s suppose you have
  insufficient quota. If you describe the Deployment you will notice the following section:
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe deployment nginx-deployment</code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>&lt;...&gt;
Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     True    ReplicaSetUpdated
  ReplicaFailure  True    FailedCreate
&lt;...&gt;</code></pre>
<p>
  If you run
  <code>
    kubectl get deployment nginx-deployment -o yaml
  </code>
  , the Deployment status is similar to this:
</p><pre><code>status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: Replica set &#34;nginx-deployment-4262182780&#34; is progressing.
    reason: ReplicaSetUpdated
    status: &#34;True&#34;
    type: Progressing
  - lastTransitionTime: 2016-10-04T12:25:42Z
    lastUpdateTime: 2016-10-04T12:25:42Z
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: &#34;True&#34;
    type: Available
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: &#39;Error creating: pods &#34;nginx-deployment-4262182780-&#34; is forbidden: exceeded quota:
      object-counts, requested: pods=1, used: pods=3, limited: pods=2&#39;
    reason: FailedCreate
    status: &#34;True&#34;
    type: ReplicaFailure
  observedGeneration: 3
  replicas: 2
  unavailableReplicas: 2</code></pre>
<p>
  Eventually, once the Deployment progress deadline is exceeded, Kubernetes updates the status and the
  reason for the Progressing condition:
</p><pre><code>Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     False   ProgressDeadlineExceeded
  ReplicaFailure  True    FailedCreate</code></pre>
<p>
  You can address an issue of insufficient quota by scaling down your Deployment, by scaling down other
  controllers you may be running, or by increasing quota in your namespace. If you satisfy the quota
  conditions and the Deployment controller then completes the Deployment rollout, you’ll see the
  Deployment’s status update with a successful condition (
  <code>
    Status=True
  </code>
  and
  <code>
    Reason=NewReplicaSetAvailable
  </code>
  ).
</p><pre><code>Conditions:
  Type          Status  Reason
  ----          ------  ------
  Available     True    MinimumReplicasAvailable
  Progressing   True    NewReplicaSetAvailable</code></pre>
<p>
  <code>
    Type=Available
  </code>
  with
  <code>
    Status=True
  </code>
  means that your Deployment has minimum availability. Minimum availability is dictated
  by the parameters specified in the deployment strategy.
  <code>
    Type=Progressing
  </code>
  with
  <code>
    Status=True
  </code>
  means that your Deployment
  is either in the middle of a rollout and it is progressing or that it has successfully completed its progress and the minimum
  required new replicas are available (see the Reason of the condition for the particulars - in our case
  <code>
    Reason=NewReplicaSetAvailable
  </code>
  means that the Deployment is complete).
</p>
<p>
  You can check if a Deployment has failed to progress by using
  <code>
    kubectl rollout status
  </code>
  .
  <code>
    kubectl rollout status
  </code>
  returns a non-zero exit code if the Deployment has exceeded the progression deadline.
</p>
<div class="highlight">
  <pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl rollout status deployment.v1.apps/nginx-deployment</code></pre>
</div>
<p>
  The output is similar to this:
</p><pre><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
error: deployment &#34;nginx&#34; exceeded its progress deadline
$ echo $?
1</code></pre>
<h3 id="operating-on-a-failed-deployment">
  Operating on a failed deployment
</h3>
<p>
  All actions that apply to a complete Deployment also apply to a failed Deployment. You can scale it up/down, roll back
  to a previous revision, or even pause it if you need to apply multiple tweaks in the Deployment Pod template.
</p>
<h2 id="clean-up-policy">
  Clean up Policy
</h2>
<p>
  You can set
  <code>
    .spec.revisionHistoryLimit
  </code>
  field in a Deployment to specify how many old ReplicaSets for
  this Deployment you want to retain. The rest will be garbage-collected in the background. By default,
  it is 10.
</p>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    Explicitly setting this field to 0, will result in cleaning up all the history of your Deployment
    thus that Deployment will not be able to roll back.
  </div>
</blockquote>
<h2 id="canary-deployment">
  Canary Deployment
</h2>
<p>
  If you want to roll out releases to a subset of users or servers using the Deployment, you
  can create multiple Deployments, one for each release, following the canary pattern described in
  <a href="/docs/concepts/cluster-administration/manage-deployment/#canary-deployments">
    managing resources
  </a>
  .
</p>
<h2 id="writing-a-deployment-spec">
  Writing a Deployment Spec
</h2>
<p>
  As with all other Kubernetes configs, a Deployment needs
  <code>
    apiVersion
  </code>
  ,
  <code>
    kind
  </code>
  , and
  <code>
    metadata
  </code>
  fields.
  For general information about working with config files, see
  <a href="/docs/tutorials/stateless-application/run-stateless-application-deployment/">
    deploying applications
  </a>
  ,
  configuring containers, and
  <a href="/docs/concepts/overview/working-with-objects/object-management/">
    using kubectl to manage resources
  </a>
  documents.
  The name of a Deployment object must be a valid
  <a href="/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">
    DNS subdomain name
  </a>
  .
</p>
<p>
  A Deployment also needs a
  <a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status">
    <code>
      .spec
    </code>
    section
  </a>
  .
</p>
<h3 id="pod-template">
  Pod Template
</h3>
<p>
  The
  <code>
    .spec.template
  </code>
  and
  <code>
    .spec.selector
  </code>
  are the only required field of the
  <code>
    .spec
  </code>
  .
</p>
<p>
  The
  <code>
    .spec.template
  </code>
  is a
  <a href="/docs/concepts/workloads/pods/pod-overview/#pod-templates">
    Pod template
  </a>
  . It has exactly the same schema as a
  <a href="/docs/concepts/workloads/pods/pod/">
    Pod
  </a>
  , except it is nested and does not have an
  <code>
    apiVersion
  </code>
  or
  <code>
    kind
  </code>
  .
</p>
<p>
  In addition to required fields for a Pod, a Pod template in a Deployment must specify appropriate
  labels and an appropriate restart policy. For labels, make sure not to overlap with other controllers. See
  <a href="#selector">
    selector
  </a>
  ).
</p>
<p>
  Only a
  <a href="/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">
    <code>
      .spec.template.spec.restartPolicy
    </code>
  </a>
  equal to
  <code>
    Always
  </code>
  is
  allowed, which is the default if not specified.
</p>
<h3 id="replicas">
  Replicas
</h3>
<p>
  <code>
    .spec.replicas
  </code>
  is an optional field that specifies the number of desired Pods. It defaults to 1.
</p>
<h3 id="selector">
  Selector
</h3>
<p>
  <code>
    .spec.selector
  </code>
  is an required field that specifies a
  <a href="/docs/concepts/overview/working-with-objects/labels/">
    label selector
  </a>
  for the Pods targeted by this Deployment.
</p>
<p>
  <code>
    .spec.selector
  </code>
  must match
  <code>
    .spec.template.metadata.labels
  </code>
  , or it will be rejected by the API.
</p>
<p>
  In API version
  <code>
    apps/v1
  </code>
  ,
  <code>
    .spec.selector
  </code>
  and
  <code>
    .metadata.labels
  </code>
  do not default to
  <code>
    .spec.template.metadata.labels
  </code>
  if not set. So they must be set explicitly. Also note that
  <code>
    .spec.selector
  </code>
  is immutable after creation of the Deployment in
  <code>
    apps/v1
  </code>
  .
</p>
<p>
  A Deployment may terminate Pods whose labels match the selector if their template is different
  from
  <code>
    .spec.template
  </code>
  or if the total number of such Pods exceeds
  <code>
    .spec.replicas
  </code>
  . It brings up new
  Pods with
  <code>
    .spec.template
  </code>
  if the number of Pods is less than the desired number.
</p>
<blockquote class="note">
  <div>
    <strong>
      Note:
    </strong>
    You should not create other Pods whose labels match this selector, either directly, by creating
    another Deployment, or by creating another controller such as a ReplicaSet or a ReplicationController. If you
    do so, the first Deployment thinks that it created these other Pods. Kubernetes does not stop you from doing this.
  </div>
</blockquote>
<p>
  If you have multiple controllers that have overlapping selectors, the controllers will fight with each
  other and won’t behave correctly.
</p>
<h3 id="strategy">
  Strategy
</h3>
<p>
  <code>
    .spec.strategy
  </code>
  specifies the strategy used to replace old Pods by new ones.
  <code>
    .spec.strategy.type
  </code>
  can be “Recreate” or “RollingUpdate”. “RollingUpdate” is
  the default value.
</p>
<h4 id="recreate-deployment">
  Recreate Deployment
</h4>
<p>
  All existing Pods are killed before new ones are created when
  <code>
    .spec.strategy.type==Recreate
  </code>
  .
</p>
<h4 id="rolling-update-deployment">
  Rolling Update Deployment
</h4>
<p>
  The Deployment updates Pods in a rolling update
  fashion when
  <code>
    .spec.strategy.type==RollingUpdate
  </code>
  . You can specify
  <code>
    maxUnavailable
  </code>
  and
  <code>
    maxSurge
  </code>
  to control
  the rolling update process.
</p>
<h5 id="max-unavailable">
  Max Unavailable
</h5>
<p>
  <code>
    .spec.strategy.rollingUpdate.maxUnavailable
  </code>
  is an optional field that specifies the maximum number
  of Pods that can be unavailable during the update process. The value can be an absolute number (for example, 5)
  or a percentage of desired Pods (for example, 10%). The absolute number is calculated from percentage by
  rounding down. The value cannot be 0 if
  <code>
    .spec.strategy.rollingUpdate.maxSurge
  </code>
  is 0. The default value is 25%.
</p>
<p>
  For example, when this value is set to 30%, the old ReplicaSet can be scaled down to 70% of desired
  Pods immediately when the rolling update starts. Once new Pods are ready, old ReplicaSet can be scaled
  down further, followed by scaling up the new ReplicaSet, ensuring that the total number of Pods available
  at all times during the update is at least 70% of the desired Pods.
</p>
<h5 id="max-surge">
  Max Surge
</h5>
<p>
  <code>
    .spec.strategy.rollingUpdate.maxSurge
  </code>
  is an optional field that specifies the maximum number of Pods
  that can be created over the desired number of Pods. The value can be an absolute number (for example, 5) or a
  percentage of desired Pods (for example, 10%). The value cannot be 0 if
  <code>
    MaxUnavailable
  </code>
  is 0. The absolute number
  is calculated from the percentage by rounding up. The default value is 25%.
</p>
<p>
  For example, when this value is set to 30%, the new ReplicaSet can be scaled up immediately when the
  rolling update starts, such that the total number of old and new Pods does not exceed 130% of desired
  Pods. Once old Pods have been killed, the new ReplicaSet can be scaled up further, ensuring that the
  total number of Pods running at any time during the update is at most 130% of desired Pods.
</p>
<h3 id="progress-deadline-seconds">
  Progress Deadline Seconds
</h3>
<p>
  <code>
    .spec.progressDeadlineSeconds
  </code>
  is an optional field that specifies the number of seconds you want
  to wait for your Deployment to progress before the system reports back that the Deployment has
  <a href="#failed-deployment">
    failed progressing
  </a>
  - surfaced as a condition with
  <code>
    Type=Progressing
  </code>
  ,
  <code>
    Status=False
  </code>
  .
  and
  <code>
    Reason=ProgressDeadlineExceeded
  </code>
  in the status of the resource. The Deployment controller will keep
  retrying the Deployment. In the future, once automatic rollback will be implemented, the Deployment
  controller will roll back a Deployment as soon as it observes such a condition.
</p>
<p>
  If specified, this field needs to be greater than
  <code>
    .spec.minReadySeconds
  </code>
  .
</p>
<h3 id="min-ready-seconds">
  Min Ready Seconds
</h3>
<p>
  <code>
    .spec.minReadySeconds
  </code>
  is an optional field that specifies the minimum number of seconds for which a newly
  created Pod should be ready without any of its containers crashing, for it to be considered available.
  This defaults to 0 (the Pod will be considered available as soon as it is ready). To learn more about when
  a Pod is considered ready, see
  <a href="/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">
    Container Probes
  </a>
  .
</p>
<h3 id="rollback-to">
  Rollback To
</h3>
<p>
  Field
  <code>
    .spec.rollbackTo
  </code>
  has been deprecated in API versions
  <code>
    extensions/v1beta1
  </code>
  and
  <code>
    apps/v1beta1
  </code>
  , and is no longer supported in API versions starting
  <code>
    apps/v1beta2
  </code>
  . Instead,
  <code>
    kubectl rollout undo
  </code>
  as introduced in
  <a href="#rolling-back-to-a-previous-revision">
    Rolling Back to a Previous Revision
  </a>
  should be used.
</p>
<h3 id="revision-history-limit">
  Revision History Limit
</h3>
<p>
  A Deployment’s revision history is stored in the ReplicaSets it controls.
</p>
<p>
  <code>
    .spec.revisionHistoryLimit
  </code>
  is an optional field that specifies the number of old ReplicaSets to retain
  to allow rollback. These old ReplicaSets consume resources in
  <code>
    etcd
  </code>
  and crowd the output of
  <code>
    kubectl get rs
  </code>
  . The configuration of each Deployment revision is stored in its ReplicaSets; therefore, once an old ReplicaSet is deleted, you lose the ability to rollback to that revision of Deployment. By default, 10 old ReplicaSets will be kept, however its ideal value depends on the frequency and stability of new Deployments.
</p>
<p>
  More specifically, setting this field to zero means that all old ReplicaSets with 0 replicas will be cleaned up.
  In this case, a new Deployment rollout cannot be undone, since its revision history is cleaned up.
</p>
<h3 id="paused">
  Paused
</h3>
<p>
  <code>
    .spec.paused
  </code>
  is an optional boolean field for pausing and resuming a Deployment. The only difference between
  a paused Deployment and one that is not paused, is that any changes into the PodTemplateSpec of the paused
  Deployment will not trigger new rollouts as long as it is paused. A Deployment is not paused by default when
  it is created.
</p></body></html>